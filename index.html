<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>Simple Audio Looper</title>
		<style>
			:root {
				--bg: #0f1220;
				--panel: #171a2a;
				--accent: #5eead4;
				--text: #e6e8f1;
				--muted: #9aa0b4;
			}
			* {
				box-sizing: border-box;
			}
			body {
				margin: 0;
				font-family: system-ui, -apple-system, Segoe UI, Roboto, Inter, Arial,
					sans-serif;
				background: radial-gradient(
						1200px 600px at 50% -10%,
						#1d2140,
						#0b0e1a 70%
					),
					var(--bg);
				color: var(--text);
				min-height: 100dvh;
				display: grid;
				place-items: start center;
			}
			.wrap {
				width: min(900px, 92vw);
				padding: 28px 16px 48px;
			}
			h1 {
				margin: 6px 0 18px;
				font-weight: 700;
				letter-spacing: 0.2px;
			}
			.panel {
				background: linear-gradient(180deg, #1a1e33, #14182a);
				border: 1px solid #242a42;
				border-radius: 16px;
				padding: 18px;
				box-shadow: 0 8px 28px rgba(0, 0, 0, 0.4);
			}
			.controls {
				display: grid;
				grid-template-columns: 1fr 1fr 1fr;
				gap: 12px;
				align-items: center;
			}
			.btn {
				appearance: none;
				border: 0;
				border-radius: 12px;
				padding: 16px 18px;
				font-size: 18px;
				font-weight: 700;
				cursor: pointer;
				transition: transform 0.04s ease, box-shadow 0.2s ease,
					background 0.2s ease, opacity 0.2s ease;
				box-shadow: 0 6px 18px rgba(0, 0, 0, 0.35);
				color: #0a1022;
			}
			.btn:active {
				transform: translateY(1px);
			}
			.btn[disabled] {
				opacity: 0.5;
				cursor: not-allowed;
			}
			.btn.record {
				background: linear-gradient(180deg, #ff7a7a, #ff4747);
				color: #200;
			}
			.btn.stop {
				background: linear-gradient(180deg, #7af7d6, #3be7c3);
			}
			.btn.halt {
				background: linear-gradient(180deg, #9cc2ff, #6aa0ff);
			}
			.status {
				margin-top: 10px;
				color: var(--muted);
				font-size: 14px;
				min-height: 20px;
			}
			.samples {
				margin-top: 18px;
				display: grid;
				gap: 10px;
			}
			.sample {
				display: grid;
				grid-template-columns: 1fr minmax(140px, 28%) 42px 42px;
				gap: 10px;
				align-items: center;
				background: var(--panel);
				border: 1px solid #252a40;
				border-radius: 12px;
				padding: 10px 12px;
			}
			.sample .name {
				font-weight: 600;
				color: #dbe2ff;
				font-size: 14px;
			}
			.sample .info {
				color: var(--muted);
				font-size: 12px;
			}
			.vcol {
				display: grid;
				gap: 6px;
			}
			input[type='range'] {
				width: 100%;
				accent-color: var(--accent);
			}
			.del {
				border: 0;
				background: #2a2f48;
				color: #ffb4b4;
				border-radius: 10px;
				width: 42px;
				height: 42px;
				font-size: 18px;
				cursor: pointer;
				transition: background 0.2s ease, transform 0.04s ease;
			}
			.del:hover {
				background: #353b5a;
			}
			.del:active {
				transform: translateY(1px);
			}
			.footer {
				margin-top: 18px;
				color: var(--muted);
				font-size: 12px;
				text-align: center;
			}
			@media (max-width: 600px) {
				.controls {
					grid-template-columns: 1fr;
				}
				.sample {
					grid-template-columns: 1fr 1fr 42px 42px;
				}
			}
			/* Oscilloscope */
			.scope {
				display: none;
				margin-top: 10px;
				background: #0a0d18;
				border: 1px solid #252a40;
				border-radius: 12px;
				width: 100%;
				height: 140px;
			}
			.scope.active {
				display: block;
			}
			.mute {
				border: 0;
				background: #2a2f48;
				color: #d7e3ff;
				border-radius: 10px;
				width: 42px;
				height: 42px;
				font-size: 18px;
				cursor: pointer;
				transition: background 0.2s ease, transform 0.04s ease;
			}
			.mute:hover {
				background: #353b5a;
			}
			.mute.active {
				color: #ffd28b;
				background: #3b415f;
			}
		</style>
	</head>
	<body>
		<div class="wrap">
			<h1>Simple Audio Looper</h1>
			<div class="panel">
				<div class="controls">
					<button id="recordBtn" class="btn record" aria-pressed="false">
						‚óè Record
					</button>
					<button id="stopBtn" class="btn stop" disabled>‚ñ† Stop</button>
					<button id="haltBtn" class="btn halt" disabled>
						‚èπ Stop Playback
					</button>
				</div>
				<div id="status" class="status">Ready.</div>
				<canvas id="scope" class="scope" aria-hidden="true"></canvas>
				<div id="samples" class="samples" aria-live="polite"></div>
			</div>
			<div class="footer">
				Tip: adjust levels with the sliders; click ‚úï to remove a loop.
			</div>
		</div>

		<script>
			'use strict';
			// --- Audio + Recording state ---
			let audioCtx = null;
			let masterGain = null;
			let mediaStream = null;
			let mediaRecorder = null;
			let recordingChunks = [];
			let loopCounter = 0;

			// Oscilloscope state
			let micSource = null;
			let analyser = null;
			let scopeRAF = null;
			let scopeData = null;
			let isDrawing = false;

			// Loop grid state
			let masterLenSec = null;
			let transportStartTime = null;
			let isPlaybackSuspended = false;

			/** Each loop item: { id, buffer, source, gainNode, el, userGain, muted } */
			const loops = new Map();

			// --- UI elements ---
			const recordBtn = document.getElementById('recordBtn');
			const stopBtn = document.getElementById('stopBtn');
			const haltBtn = document.getElementById('haltBtn');
			const statusEl = document.getElementById('status');
			const samplesEl = document.getElementById('samples');
			const scopeCanvas = document.getElementById('scope');
			const scopeCtx = scopeCanvas.getContext('2d');

			function setStatus(msg) {
				statusEl.textContent = msg;
			}

			function ensureAudio() {
				if (!audioCtx) {
					audioCtx = new (window.AudioContext || window.webkitAudioContext)();
					masterGain = audioCtx.createGain();
					masterGain.gain.value = 1.0;
					masterGain.connect(audioCtx.destination);
					if (haltBtn) {
						haltBtn.disabled = false;
						updateHaltButtonUI();
					}
				}
			}

			async function getMicStream() {
				if (mediaStream && mediaStream.active) {
					return mediaStream;
				}
				try {
					mediaStream = await navigator.mediaDevices.getUserMedia({
						audio: {
							echoCancellation: false,
							noiseSuppression: false,
							autoGainControl: false,
						},
						video: false,
					});
					return mediaStream;
				} catch (err) {
					console.error(err);
					setStatus(
						'Mic access failed. Please allow permission and try again.'
					);
					throw err;
				}
			}

			function pickMimeType() {
				const candidates = [
					'audio/webm;codecs=opus',
					'audio/ogg;codecs=opus',
					'audio/webm',
					'audio/ogg',
				];
				for (const t of candidates) {
					if (
						window.MediaRecorder &&
						MediaRecorder.isTypeSupported &&
						MediaRecorder.isTypeSupported(t)
					) {
						return t;
					}
				}
				return '';
			}

			// ---- Oscilloscope helpers ----
			function ensureAnalyser(stream) {
				if (!audioCtx) return;
				if (!micSource) {
					micSource = audioCtx.createMediaStreamSource(stream);
					analyser = audioCtx.createAnalyser();
					analyser.fftSize = 2048;
					analyser.smoothingTimeConstant = 0.85;
					micSource.connect(analyser);
					scopeData = new Uint8Array(analyser.frequencyBinCount);
				}
			}

			function startScope() {
				if (!analyser) return;
				isDrawing = true;
				scopeCanvas.classList.add('active');
				scopeCanvas.setAttribute('aria-hidden', 'false');
				drawScope();
			}

			function stopScope() {
				isDrawing = false;
				if (scopeRAF) {
					cancelAnimationFrame(scopeRAF);
					scopeRAF = null;
				}
				try {
					scopeCtx.clearRect(0, 0, scopeCanvas.width, scopeCanvas.height);
				} catch (_) {
					/* no-op */
				}
				scopeCanvas.classList.remove('active');
				scopeCanvas.setAttribute('aria-hidden', 'true');
			}

			function drawScope() {
				if (!isDrawing || !analyser) return;
				const dpr = window.devicePixelRatio || 1;
				const cssW = scopeCanvas.clientWidth || 600;
				const cssH = scopeCanvas.clientHeight || 140;
				const needResize =
					scopeCanvas.width !== Math.floor(cssW * dpr) ||
					scopeCanvas.height !== Math.floor(cssH * dpr);
				if (needResize) {
					scopeCanvas.width = Math.floor(cssW * dpr);
					scopeCanvas.height = Math.floor(cssH * dpr);
					scopeCtx.setTransform(dpr, 0, 0, dpr, 0, 0);
				}

				analyser.getByteTimeDomainData(scopeData);

				scopeCtx.clearRect(0, 0, cssW, cssH);
				scopeCtx.beginPath();
				const mid = cssH / 2;
				const step = cssW / scopeData.length;
				for (let i = 0; i < scopeData.length; i++) {
					const v = (scopeData[i] - 128) / 128; // -1..1
					const x = i * step;
					const y = mid + v * (cssH * 0.45);
					if (i === 0) scopeCtx.moveTo(x, y);
					else scopeCtx.lineTo(x, y);
				}
				scopeCtx.lineWidth = 2;
				scopeCtx.strokeStyle = '#79ffe1';
				scopeCtx.stroke();

				scopeRAF = requestAnimationFrame(drawScope);
			}

			window.addEventListener('resize', () => {
				if (scopeCanvas.classList.contains('active')) {
					drawScope();
				}
			});

			async function startRecording() {
				ensureAudio();
				await audioCtx.resume();
				const stream = await getMicStream();
				ensureAnalyser(stream);
				startScope();
				const options = {};
				const mt = pickMimeType();
				if (mt) {
					options.mimeType = mt;
				}
				try {
					mediaRecorder = new MediaRecorder(stream, options);
				} catch (e) {
					console.error(e);
					setStatus('Recording is not supported in this browser.');
					return;
				}

				recordingChunks = [];
				mediaRecorder.ondataavailable = (e) => {
					if (e.data && e.data.size > 0) {
						recordingChunks.push(e.data);
					}
				};
				mediaRecorder.onstop = handleRecordingStop;
				mediaRecorder.start();

				recordBtn.disabled = true;
				recordBtn.setAttribute('aria-pressed', 'true');
				stopBtn.disabled = false;
				setStatus('Recording‚Ä¶ Click Stop to end.');
			}

			async function stopRecording() {
				if (mediaRecorder && mediaRecorder.state === 'recording') {
					stopScope();
					mediaRecorder.stop();
					stopBtn.disabled = true;
					setStatus('Processing‚Ä¶');
				}
			}

			function decodeSafely(arrayBuffer) {
				// Some browsers require a copy of the ArrayBuffer for decodeAudioData.
				const ab = arrayBuffer.slice(0);
				return new Promise((resolve, reject) => {
					audioCtx.decodeAudioData(ab, resolve, reject);
				});
			}

			// --- Per-track gain helpers (fixes Mute + slider) ---
			function effectiveGain(userGain, muted) {
				return muted ? 0 : userGain;
			}
			function applyGain(item) {
				if (!item || !item.gainNode) return;
				const ug = item.userGain ?? 1.0;
				const m = item.muted ?? false;
				item.gainNode.gain.value = effectiveGain(ug, m);
			}

			// --- Loop alignment helpers ---
			function padToMultiple(buffer, baseSec, ctx = audioCtx) {
				const rate = buffer.sampleRate;
				const base = Math.max(1, Math.round(baseSec * rate));
				const cur = buffer.length;
				const multiple = Math.max(1, Math.ceil(cur / base));
				const newLen = multiple * base;
				if (newLen === cur) return buffer;
				const out = ctx.createBuffer(buffer.numberOfChannels, newLen, rate);
				for (let ch = 0; ch < buffer.numberOfChannels; ch++) {
					out.getChannelData(ch).set(buffer.getChannelData(ch));
				}
				return out;
			}

			function nextGridTime(now) {
				if (transportStartTime == null || masterLenSec == null)
					return now + 0.05;
				const lookahead = 0.05;
				const elapsed = now - transportStartTime;
				if (elapsed < -0.001) return transportStartTime + 0.05;
				const cycles = Math.ceil((elapsed + lookahead) / masterLenSec);
				return transportStartTime + cycles * masterLenSec;
			}

			async function resampleToContext(buffer, targetRate) {
				if (!buffer || buffer.sampleRate === targetRate) return buffer;
				const offline = new OfflineAudioContext(
					buffer.numberOfChannels,
					Math.ceil(buffer.duration * targetRate),
					targetRate
				);
				const src = offline.createBufferSource();
				src.buffer = buffer;
				src.connect(offline.destination);
				src.start(0);
				const rendered = await offline.startRendering();
				return rendered;
			}

			function startLoopNode(buffer, when) {
				const id = `loop-${++loopCounter}`;
				const source = audioCtx.createBufferSource();
				source.buffer = buffer;
				source.loop = true;
				const gainNode = audioCtx.createGain();
				const userGain = 1.0;
				const muted = false;
				gainNode.gain.value = userGain;
				source.connect(gainNode).connect(masterGain);
				source.start(when);
				const el = renderSampleItem({ id, duration: buffer.duration });
				return { id, buffer, source, gainNode, el, userGain, muted };
			}

			async function addLoop(buffer) {
				// Ensure buffer uses the AudioContext sample rate
				buffer = await resampleToContext(buffer, audioCtx.sampleRate);

				if (masterLenSec == null) {
					// First loop: establish the grid and transport
					masterLenSec = buffer.duration;
					buffer = padToMultiple(buffer, masterLenSec);
					transportStartTime = audioCtx.currentTime + 0.2; // small scheduling lookahead
					const node = startLoopNode(buffer, transportStartTime);
					loops.set(node.id, node);
					setStatus('First loop set as master. New loops will align to it.');
				} else {
					// Subsequent loops: extend to an integer multiple and start on next boundary
					buffer = padToMultiple(buffer, masterLenSec);
					const startAt = nextGridTime(audioCtx.currentTime);
					const node = startLoopNode(buffer, startAt);
					loops.set(node.id, node);
					const eta = Math.max(
						0,
						Math.round((startAt - audioCtx.currentTime) * 1000)
					);
					setStatus(`Loop added; starts at next boundary in ~${eta} ms.`);
				}
			}

			async function handleRecordingStop() {
				try {
					const blob = new Blob(recordingChunks, {
						type: mediaRecorder.mimeType || 'audio/webm',
					});
					const ab = await blob.arrayBuffer();
					const buffer = await decodeSafely(ab);
					await addLoop(buffer);
				} catch (err) {
					console.error(err);
					setStatus('Could not decode audio. Please try another recording.');
				} finally {
					recordBtn.disabled = false;
					recordBtn.setAttribute('aria-pressed', 'false');
				}
			}

			function renderSampleItem({ id, duration }) {
				const row = document.createElement('div');
				row.className = 'sample';
				row.id = id;

				const name = document.createElement('div');
				name.className = 'name';
				name.textContent = `Sample ${id.split('-')[1]}`;

				const info = document.createElement('div');
				info.className = 'info';
				info.textContent = `${duration.toFixed(2)} s loop`;

				const labelCol = document.createElement('div');
				labelCol.appendChild(name);
				labelCol.appendChild(info);

				const vcol = document.createElement('div');
				vcol.className = 'vcol';
				const slider = document.createElement('input');
				slider.type = 'range';
				slider.min = '0';
				slider.max = '100';
				slider.value = '100';
				slider.setAttribute('aria-label', 'Level');
				vcol.appendChild(slider);

				const del = document.createElement('button');
				del.className = 'del';
				del.title = 'Delete loop';
				del.setAttribute('aria-label', 'Delete loop');
				del.textContent = '‚úï';

				row.appendChild(labelCol);
				row.appendChild(vcol);
				const mute = document.createElement('button');
				mute.className = 'mute';
				mute.title = 'Mute/unmute';
				mute.setAttribute('aria-pressed', 'false');
				mute.textContent = 'üîà';
				row.appendChild(mute);
				row.appendChild(del);

				mute.addEventListener('click', () => {
					const item = loops.get(id);
					if (!item) return;
					item.muted = !item.muted;
					mute.classList.toggle('active', item.muted);
					mute.setAttribute('aria-pressed', String(item.muted));
					mute.textContent = item.muted ? 'üîá' : 'üîà';
					applyGain(item);
				});
				samplesEl.appendChild(row);

				// Wire events
				slider.addEventListener('input', () => {
					const item = loops.get(id);
					if (item) {
						item.userGain = parseInt(slider.value, 10) / 100;
						applyGain(item);
					}
				});

				del.addEventListener('click', () => removeLoop(id));
				return row;
			}

			function removeLoop(id) {
				const item = loops.get(id);
				if (!item) {
					return;
				}
				try {
					item.source.stop();
				} catch (_) {
					/* no-op */
				}
				try {
					item.source.disconnect();
				} catch (_) {
					/* no-op */
				}
				try {
					item.gainNode.disconnect();
				} catch (_) {
					/* no-op */
				}
				if (item.el && item.el.parentNode) {
					item.el.parentNode.removeChild(item.el);
				}
				loops.delete(id);
				if (loops.size === 0) {
					masterLenSec = null;
					transportStartTime = null;
				}
				setStatus('Loop removed.');
			}

			function teardown() {
				// Stop all sources and clear list
				for (const [, item] of loops) {
					try {
						item.source.stop();
					} catch (_) {}
				}
				loops.clear();

				// Stop and disconnect oscilloscope
				stopScope();
				if (micSource) {
					try {
						micSource.disconnect();
					} catch (_) {}
					micSource = null;
				}
				if (analyser) {
					try {
						analyser.disconnect();
					} catch (_) {}
					analyser = null;
				}

				if (haltBtn) {
					haltBtn.disabled = true;
				}
				isPlaybackSuspended = false;
			}

			// --- Playback Halt/Resume ---
			function updateHaltButtonUI() {
				if (!haltBtn) return;
				haltBtn.textContent = isPlaybackSuspended
					? '‚ñ∂ Resume Playback'
					: '‚èπ Stop Playback';
			}

			if (haltBtn) {
				haltBtn.addEventListener('click', async () => {
					ensureAudio();
					if (!audioCtx) return;
					try {
						if (!isPlaybackSuspended) {
							// Soft-mute master immediately
							masterGain.gain.setTargetAtTime(0, audioCtx.currentTime, 0.01);
							// Also try to suspend the context (browser may ignore)
							try {
								await audioCtx.suspend();
							} catch (_) {}
							isPlaybackSuspended = true;
							setStatus('Playback suspended.');
						} else {
							// Resume context first, then unmute master
							try {
								await audioCtx.resume();
							} catch (_) {}
							masterGain.gain.setTargetAtTime(1, audioCtx.currentTime, 0.01);
							isPlaybackSuspended = false;
							setStatus('Playback resumed.');
						}
						updateHaltButtonUI();
					} catch (e) {
						console.error(e);
					}
				});
			}

			// --- Hook up UI ---
			recordBtn.addEventListener('click', async () => {
				try {
					await startRecording();
				} catch (e) {
					console.error(e);
				}
			});

			stopBtn.addEventListener('click', () => {
				stopRecording();
			});

			// Resume AudioContext on any user gesture if suspended.
			['click', 'touchstart', 'keydown'].forEach((evt) => {
				window.addEventListener(
					evt,
					() => {
						if (audioCtx && audioCtx.state === 'suspended') {
							audioCtx.resume();
						}
					},
					{ once: false, passive: true }
				);
			});

			window.addEventListener('beforeunload', teardown);

			// ---------------------------
			// Minimal self-tests (console)
			// ---------------------------
			(async function runSelfTests() {
				try {
					console.groupCollapsed('%cLooper self-tests', 'color:#5eead4');
					// Test: padToMultiple extends to the next multiple
					const tmp1 = new OfflineAudioContext(1, 62400, 48000); // 1.3 s at 48k
					const buf1 = tmp1.createBuffer(1, 62400, 48000);
					const baseSec = 0.5; // 24k frames per unit
					const padded = padToMultiple(buf1, baseSec, tmp1);
					console.assert(
						padded.length === 72000,
						'padToMultiple should extend to 72000 frames'
					);

					// Test: nextGridTime snaps to boundaries with lookahead
					transportStartTime = 100;
					masterLenSec = 0.5;
					let t = nextGridTime(100.1);
					console.assert(
						Math.abs(t - 100.5) < 1e-6,
						'nextGridTime should return 100.5'
					);
					t = nextGridTime(100.51);
					console.assert(
						Math.abs(t - 101.0) < 1e-6,
						'nextGridTime should return 101.0'
					);

					// Test: resampleToContext changes sampleRate
					const srcCtx = new OfflineAudioContext(1, 32000, 32000);
					const srcBuf = srcCtx.createBuffer(1, 16000, 32000); // 0.5 s at 32k
					const res = await resampleToContext(srcBuf, 48000);
					console.assert(
						res.sampleRate === 48000,
						'resampleToContext should output at 48k'
					);

					// New tests: effectiveGain/applyGain + padToMultiple no-op when multiple
					console.assert(
						effectiveGain(0.7, false) === 0.7,
						'effectiveGain should pass through when not muted'
					);
					console.assert(
						effectiveGain(0.7, true) === 0,
						'effectiveGain should be 0 when muted'
					);
					const mock = {
						gainNode: { gain: { value: 1 } },
						userGain: 0.5,
						muted: false,
					};
					applyGain(mock);
					console.assert(
						mock.gainNode.gain.value === 0.5,
						'applyGain should set user gain'
					);
					mock.muted = true;
					applyGain(mock);
					console.assert(
						mock.gainNode.gain.value === 0,
						'applyGain should mute'
					);

					const tmp2 = new OfflineAudioContext(1, 48000, 48000);
					const buf2 = tmp2.createBuffer(1, 48000, 48000);
					const padded2 = padToMultiple(buf2, 1.0, tmp2);
					console.assert(
						padded2.length === 48000,
						'padToMultiple should not change when already exact multiple'
					);
					console.groupEnd();
				} catch (e) {
					console.error('Self-tests failed:', e);
				} finally {
					// Reset grid vars used in tests
					masterLenSec = null;
					transportStartTime = null;
				}
			})();
		</script>
	</body>
</html>
